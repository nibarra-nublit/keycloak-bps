## 1. Diagnóstico de errores de autenticación

### 1.1 Análisis de logs de autenticación en Keycloak

Keycloak registra eventos de autenticación que permiten identificar fallos de inicio de sesión. Por defecto, el _Logging Event Listener_ de Keycloak está habilitado, lo que hace que cada error de login se escriba en el log con detalles del evento. Estas entradas suelen aparecer con la categoría de logger `org.keycloak.events` en nivel WARN.

Por ejemplo, ante un intento de autenticación fallido por credenciales inválidas, el log puede mostrar una línea como la siguiente:

```
... WARN  [org.keycloak.events] ... type=LOGIN_ERROR, realmId=master, clientId=myapp, userId=<ID usuario>, ipAddress=127.0.0.1, error=invalid_user_credentials, auth_method=openid-connect, ...
```

En este caso se indica `type=LOGIN_ERROR` con `error=invalid_user_credentials` (credenciales de usuario inválidas)​. Los campos incluyen el realm, cliente, usuario (ID), IP de origen y tipo de autenticación, lo cual ayuda a diagnosticar qué falló. Otros errores comunes en este campo `error` pueden ser `user_not_found` (usuario no existe) o `user_disabled` (usuario inhabilitado)​ según la causa del problema.

**Comandos para revisar logs**: Si Keycloak está ejecutándose en Docker, se pueden inspeccionar los logs con:

```bash
docker logs -f <nombre_contenedor_keycloak>
```

y filtrar los mensajes relevantes, por ejemplo:

```bash
docker logs <contenedor> 2>&1 | grep "LOGIN_ERROR"
```

En entornos tradicionales, el log de servidor (por ejemplo, `keycloak.log` o `server.log`) puede monitorearse con `tail -f`. Es recomendable buscar palabras clave como `ERROR` o el nombre del evento (`LOGIN_ERROR`) para ubicar rápidamente fallos de autenticación.

Adicionalmente, Keycloak cuenta con un visor de eventos en la consola de administración (sección **Eventos de inicio de sesión** del Realm) que muestra los intentos de login y sus errores, aunque la inspección directa de logs ofrece información más detallada en tiempo real.

### 1.2 Uso de métricas en Grafana para identificar patrones de fallos

Si las métricas de Keycloak están habilitadas (expuestas para Prometheus) y Grafana está configurado, podemos utilizar paneles o consultas PromQL para detectar patrones en los errores de autenticación. Keycloak provee métricas de eventos de usuario a través de su endpoint de métricas. Una métrica clave es `keycloak_user_events_total`, que contabiliza eventos de usuario (login, logout, etc.) con etiquetas como el tipo de evento, el realm e incluso el error ocurrido
Por ejemplo, un login exitoso incrementa el contador con `event="login"` y `error=""` (cadena vacía en error), mientras que un login fallido incrementará el contador con `event="login"` y un código de error específico. A continuación se muestra un fragmento de esta métrica donde se registró un intento de login fallido por credenciales inválidas (`error="invalid_user_credentials"`):

```
# HELP keycloak_user_events_total Keycloak user events # 
TYPE keycloak_user_events_total counter keycloak_user_events_total{client_id="security-admin-console",error="invalid_user_credentials",event="login",idp="",realm="master"} 1.0
```

En el ejemplo, el valor `1.0` indica un evento (un intento de login) con error de credenciales inválidas en el realm "master"​. Podemos aprovechar estos datos para visualizar tendencias.

**Consultas PromQL útiles**: en Grafana, podríamos usar consultas como:

- **Tasa de logins fallidos**:
    
```promql
rate(keycloak_user_events_total{event="login", error!=""}[5m])
```
    
    Esta consulta calcula la tasa de eventos de login con error en una ventana de 5 minutos, lo que permite ver si hay picos anómalos de fallos.
    
- **Conteo de errores por tipo**:
    
```promql
sum by(error) (increase(keycloak_user_events_total{event="login"}[5m]))
```
    
    Esto sumaría los eventos de login en 5 minutos agrupados por etiqueta de error, facilitando identificar cuál es el error más frecuente (ejemplo: muchos `invalid_user_credentials` indicando quizá intentos con contraseña incorrecta o ataques de fuerza bruta).

En los paneles de Grafana, estas métricas ayudan a diagnosticar patrones: por ejemplo, un aumento repentino de `invalid_user_credentials` podría indicar un problema generalizado de credenciales (o un usuario que olvidó su contraseña intentando repetidamente), mientras que errores `user_not_found` constantes podrían señalar que una aplicación está consultando con un nombre de usuario incorrecto. Si los valores normales de estas métricas (base line) se ven alterados, Grafana puede incluso lanzar alertas.

**Nota**: Las métricas de eventos de usuario pueden requerir habilitación explícita en Keycloak (por defecto, en algunas versiones, la recolección de eventos para métricas está deshabilitada para reducir cardinalidad​). Asegúrese de habilitar las métricas de eventos de login si desea monitorear estos errores via Prometheus/Grafana.

### 1.3 Interpretación de trazas distribuidas (OpenTelemetry)

Si OpenTelemetry está habilitado en Keycloak (tracing distribuido), cada solicitud de autenticación puede generar una _traza_ que detalla el recorrido de dicha petición a través de los componentes internos de Keycloak e incluso servicios externos. El tracing proporciona visibilidad a nivel de cada paso o _span_ del flujo de autenticación​.

En el contexto de un error de autenticación, las trazas permiten:

- **Identificar el punto exacto de fallo**: por ejemplo, una traza de un login fallido podría mostrar spans para la solicitud HTTP entrante, la verificación de credenciales contra la base de usuarios (o LDAP), etc., y en el span correspondiente se marcará un error o excepción en caso de credenciales inválidas. Keycloak crea spans para actividades como peticiones HTTP entrantes, llamadas a base de datos, consultas LDAP y peticiones HTTP salientes a servicios externos (por ejemplo, proveedores de identidad)​. De esta manera, si el fallo provino de la base de datos de usuarios o de un proveedor externo, se verá claramente en la traza.
    
- **Ver eventos y logs dentro de la traza**: Cuando una traza es muestreada (capturada), incluye los eventos de usuario ocurridos durante la solicitud​. Por ejemplo, un evento de `LOGIN_ERROR` aparecerá embebido en la traza con todos sus detalles (realm, cliente, error, etc.). Esto significa que al inspeccionar la traza en una herramienta como Jaeger o Grafana Tempo, podemos encontrar una entrada de log dentro de la traza indicando `error=invalid_user_credentials` si ese fue el problema, sin tener que buscar por separado en los logs​. Asimismo, errores en la comunicación con LDAP u otros servicios se adjuntan a la traza con su stacktrace​, lo que agiliza el diagnóstico de fallos más complejos.
    
- **Correlacionar con logs tradicionales**: Cuando el tracing está habilitado, Keycloak añade el identificador de traza (`traceId`) a cada línea de log correspondiente a esa petición​. Por ejemplo, una entrada de log podría comenzar con `traceId=abc123...` seguida del mensaje. Esto permite que, al ver un error en el log, podamos buscar el mismo `traceId` en la herramienta de trazas y obtener la historia completa de la solicitud problemática. Todos los mensajes de log generados por la misma solicitud comparten el mismo `traceId`, facilitando la trazabilidad end-to-end.
    

**Interpretación práctica**: En una herramienta de visualización (Jaeger, Grafana), para un error de autenticación buscaríamos trazas del servicio "keycloak" filtrando por operaciones de login o por etiquetas (por ejemplo, filtrando por `kc.error` si existiera, o encontrando spans marcados con código de respuesta 401/403). En Jaeger, seleccionar el servicio "keycloak" y buscar trazas donde el _operation name_ sea la URL de autenticación (p.ej. `/realms/<realm>/protocol/openid-connect/auth`) puede listar intentos. Al abrir una traza específica, podremos ver la secuencia: un span para la solicitud entrante, luego quizás un span de autenticación interna. Si algo falló, un span podría aparecer resaltado como error o con anotaciones rojas, y al expandirlo veríamos que contiene un log con el mensaje de error de Keycloak.

En suma, las trazas con OpenTelemetry ofrecen una vista detallada paso a paso de los flujos de autenticación y son especialmente útiles cuando los problemas son intermitentes o involucran múltiples componentes, ya que agilizan la identificación del punto de fallo exacto y su causa.

## 2. Solución de problemas de configuración de clientes (OIDC/SAML)

Los problemas de configuración de clientes (ya sean clientes OIDC o integraciones SAML) suelen manifestarse como errores durante el proceso de autenticación o intercambio de tokens, a veces antes incluso de que el usuario ingrese credenciales. A continuación, se detalla cómo diagnosticar estos casos mediante logs, métricas y trazas.

### 2.1 Revisión de logs para errores en configuración de clientes OIDC

En integraciones OpenID Connect (OIDC), una configuración incorrecta del cliente puede generar distintos errores. Algunos ejemplos típicos y lo que veríamos en los logs:

- **URI de redirección inválida**: Si la aplicación redirige al usuario a Keycloak con una `redirect_uri` que no coincide con las URIs permitidas configuradas en el cliente, Keycloak abortará el flujo y mostrará un mensaje de error en pantalla del tipo _"Invalid parameter: redirect_uri"_ (Parámetro redirect_uri inválido). En el log del servidor, esto puede registrarse como una advertencia. Es posible que no aparezca como un `LOGIN_ERROR` (puesto que el usuario no llegó a autenticarse), pero sí suele haber una entrada indicando el fallo de validación del parámetro. Por ejemplo, usar un esquema o hostname no autorizado produce este error. Si observamos los logs con nivel DEBUG para OIDC, veríamos detalles de la comparación de la URL proporcionada vs las registradas.
    
    **Diagnóstico**: Ante este mensaje, verificar la configuración del cliente en Keycloak (campo "Valid Redirect URIs"). Asegurarse de que la URL exacta utilizada por la aplicación (incluyendo puerto, path y si aplica, el protocolo http/https) esté incluida. Un error común es olvidar incluir un dominio alternativo (ej. usar "localhost" en la config pero la app redirige con "127.0.0.1")​. Los logs ayudan a confirmar que Keycloak rechazó la solicitud por este motivo. En caso de duda, se puede habilitar logging a nivel DEBUG para la categoría OIDC (`org.keycloak.protocol.oidc`) y reproducir el fallo, lo que mostrará en el log las URIs esperadas vs la recibida, facilitando identificar la discrepancia.
    
- **Cliente no encontrado o credenciales inválidas**: Si una aplicación intenta obtener un token usando un _client id_ incorrecto o un _client secret_ erróneo (por ejemplo, en un flujo de _Client Credentials_ o al canjear un código por token), Keycloak retornará un error `invalid_client` al cliente. En los logs del servidor, este evento queda registrado. De hecho, Keycloak maneja los _login_ de clientes (autenticación de cliente) como eventos que también pueden aparecer en los logs de eventos o métricas. Un intento de token con client secret incorrecto puede producir un evento con `error=invalid_client_credentials`, mientras que un client ID inválido podría generar `error=client_not_found`.

    **Diagnóstico**: Revisar el log en busca de entradas de tipo error alrededor del momento en que la aplicación falla al autenticarse. Si el _Logging Event Listener_ está activo para eventos de administrador, estos podrían aparecer de forma estructurada similar a los de usuario. De no ser así, aumentar nivel de log puede mostrar mensajes como "Client authentication failed: client not found" o "Client secret invalid for client X". En cualquier caso, la acción es verificar que el cliente exista en el realm correcto, que el `client_id` utilizado coincida exactamente (incluyendo mayúsculas/minúsculas), y que el secreto configurado en la aplicación sea el mismo que el que Keycloak tiene registrado.
    
  - **Errores en parámetros OIDC**: Otros posibles fallos de configuración incluyen discrepancias en algoritmos de firma, scopes no permitidos, etc. Por ejemplo, si el cliente solicita scopes no consentidos, Keycloak podría denegar la solicitud con un error. En los logs de nivel DEBUG, se vería información sobre la validación de scopes. La solución en estos casos suele ser ajustar la configuración del cliente (añadir scopes necesarios, configurar algoritmos de ID Token compatibles, etc.).
    

Para todos estos casos, los logs son la primera fuente de verdad. A menudo, el mensaje de error de Keycloak en el log es descriptivo. **Ejemplo**: _"Client clienteX not found in realm realmY"_ indica uso de un client ID equivocado o realm incorrecto; _"Invalid client credentials"_ indica un secreto inválido o ausente en la solicitud. Mantener el log en nivel INFO o WARN suele ser suficiente para ver estos mensajes, pero de no ser claros, escalar a DEBUG para categorías relevantes (ej. `org.keycloak.services` y `org.keycloak.protocol.oidc`) dará más contexto.

En entornos SAML, la depuración por logs también es crucial, pero difiere ligeramente dado que el flujo SAML es redireccional y basado en XML firmado.

### 2.2 Revisión de logs para errores en configuración de clientes SAML

Cuando Keycloak actúa como IdP SAML, los problemas de configuración con el SP (Service Provider) pueden manifestarse en distintas etapas del flujo SAML:

- **Errores de firma y certificados**: Uno de los fallos más comunes es la discrepancia en la configuración de firmas. Por ejemplo, si Keycloak está configurado para requerir que las _AuthnRequests_ del SP estén firmadas o que las respuestas/assertions SAML estén firmadas, pero el lado del SP no está enviando la firma o no la valida correctamente, se producirá un error. Keycloak, al recibir una solicitud SAML no firmada cuando espera firma, podría rechazarla con un mensaje de error genérico como "Invalid Requester". Del lado del SP, podría registrarse un error de firma inválida. En entornos de depuración (DEBUG), Keycloak indicaría algo como _"Request rejected: either the Response or Assertion must be signed"_​.
    
    **Diagnóstico**: Verificar las opciones de firma en la configuración del cliente SAML en Keycloak (por ejemplo, las opciones "Sign Assertions" y "Sign Documents") y en la configuración del SP. Si los logs (ya sea de Keycloak en DEBUG o del SP) muestran mensajes que mencionan requisitos de firma, es indicativo de esta desalineación​. La solución es asegurar que ambos lados tienen la misma expectativa: o bien desactivar la exigencia de firma en Keycloak si el SP no firma sus solicitudes, o habilitar la firma en el SP y proporcionar el certificado correspondiente a Keycloak. Asimismo, revisar que el _Certificate_ configurado para validar firmas en Keycloak coincida con el certificado usado por el SP para firmar.
    
- **URL de endpoint o Issuer incorrectos**: En SAML, el IdP (Keycloak) identifica al SP por el _Issuer_ (Entidad ID) en las peticiones. Si este identificador no coincide exactamente con el configurado en el cliente SAML de Keycloak, las peticiones serán rechazadas. Un síntoma típico es un error "Invalid requester." en Keycloak, lo que significa que el Issuer de la AuthnRequest no coincide con ningún cliente conocido. En logs DEBUG de Keycloak, se puede ver el issuer recibido y quizás un mensaje de que no se encontró cliente para ese issuer. Para solucionarlo, asegurarse de configurar en Keycloak el mismo **Entity ID** que usa el SP en sus mensajes (a menudo la URL de metadata del SP).
    
- **Otros atributos SAML**: Si el SP espera ciertos atributos en la aserción (por ejemplo, NameID en formato específico, o atributos de grupo) y Keycloak no los envía, la autenticación podría considerarse incompleta en el SP. Estos problemas no siempre generan un error en Keycloak (desde su perspectiva la autenticación puede ser _exitosa_), pero en la práctica el usuario no accede correctamente. Aquí, la clave es más la configuración que los logs: revisar mapeos de atributos, formato NameID, etc. Los logs DEBUG pueden ayudar mostrando qué atributos se están incluyendo en la respuesta SAML.
    

Para depurar SAML de forma efectiva, es aconsejable habilitar logs más verbosos en categorías SAML. Por ejemplo, ejecutar Keycloak con `--log-level=org.keycloak.protocol.saml:DEBUG` proporcionará trazas detalladas de procesamiento SAML, incluyendo validación de firma, coincidencia de issuer, etc. Esto permite ver paso a paso dónde podría estar fallando la comunicación con el SP.

### 2.3 Métricas y trazas para problemas entre clientes y Keycloak

**Métricas**: Al igual que con los logins de usuarios, Keycloak puede exponer métricas relacionadas con la autenticación de clientes. Si se cuenta con el SPI de métricas o la funcionalidad incorporada, habrá contadores para intentos de inicio de sesión de clientes (_client logins_). Por ejemplo, la métrica `keycloak_failed_client_login_attempts` (del SPI de métricas comunitario) contabiliza intentos de login de clientes fallidos, distinguiendo errores como `invalid_client_credentials` o `client_not_found`. En Grafana, esta métrica (o una equivalente oficial si existe) podría graficarse para vigilar errores de autenticación de clientes a lo largo del tiempo. Un incremento en `client_not_found` podría indicar que alguna integración está usando un client ID incorrecto repetidamente, mientras que valores de `invalid_client_credentials` sugieren un secreto desactualizado o mal configurado en la aplicación cliente.

Por otro lado, para errores como `redirect_uri` inválido, no habrá una métrica de evento de login ya que no se concretó un intento de login. Sin embargo, podríamos apoyarnos en métricas de nivel de protocolo si están disponibles (por ejemplo, conteos de respuestas HTTP 400/401 en endpoints de autorización/token). Keycloak explicita ciertos indicadores en métricas que podrían ser útiles para SLOs (Service Level Objectives) – por ejemplo, total de tokens emitidos vs errores emitidos – aunque estos son más generales.

**Traces**: La trazabilidad distribuida también es valiosa en problemas de comunicación cliente-Keycloak. Consideremos dos situaciones:

- _Flujo de código OIDC (Authorization Code Flow)_: Este flujo involucra múltiples pasos (autorización, redirección con code, canje de code por token). Con tracing habilitado, podemos seguir todo el flujo. Tras el login, el cliente (aplicación) realiza una petición al endpoint `/token` de Keycloak para obtener tokens usando el código otorgado. En la traza, habrá un span para esa petición HTTP entrante al `/token`. Si la configuración del cliente es errónea (por ejemplo, client secret incorrecto), ese span podría terminar con un error (código HTTP 401) y contendrá en sus _logs internos_ la razón (`invalid_client_credentials`). Esto nos confirmaría que el fallo ocurrió en la fase de intercambio del código por token. De igual forma, un error de redirect URI inválido se reflejaría en la traza como una interrupción tras el intento inicial de autorización – es posible que veamos el span de la petición de autorización terminando rápidamente con un código de error, sin transiciones a otros spans como el de autenticación de usuario (puesto que no llegó a ese punto).
    
- _Flujo SAML_: En una traza de una autenticación SAML, veríamos la petición HTTP entrante al endpoint SAML de Keycloak. Si la petición es rechazada tempranamente (por ejemplo, issuer no válido o firma faltante), la traza será corta: quizás solo el span de la solicitud entrante con una marca de error. Dentro de ese span, en los _logs_ adjuntos, podríamos encontrar la indicación del problema (por ejemplo, un log interno diciendo _"Requester not allowed"_ o detallando el fallo de validación). Si la autenticación procede más (usuario ingresa credenciales) pero falla al generar/responder al SP, la traza incluirá los pasos de login de usuario y luego mostrará un error al intentar generar la respuesta SAML.    

En resumen, las _trazas_ complementan a los logs tradicionales al ofrecer contexto secuencial. Para diagnosticar fallos en la comunicación cliente-Keycloak, podemos usar trazas para ver: a) qué solicitudes hizo el cliente y cómo respondió Keycloak, b) en qué punto exacto se produjo un error y con qué detalle (gracias a los logs incrustados), y c) correlacionar con cualquier interacción externa (p.ej., Keycloak como broker OIDC hacia otro IdP, aunque eso sale del alcance de cliente directo).

Por último, es importante mencionar que habilitar tracing y métricas no sustituye a revisar la configuración: una vez que las herramientas indican el posible fallo (sea un error de configuración de URIs, credenciales, firmas, etc.), la solución viene de corregir la configuración del cliente en Keycloak o en la aplicación para alinearlas. En la siguiente sección, veremos cómo aumentar el detalle de logs en Keycloak y aprovechar formatos avanzados para depuración más profunda.

## 3. Depuración de flujos de autenticación y logs avanzados

Cuando los problemas no son evidentes con los logs en nivel por defecto, es útil recurrir a técnicas avanzadas: elevar el nivel de log para ciertas categorías, habilitar formato estructurado de logs (JSON) para su análisis con herramientas externas, e integrar Keycloak con sistemas centralizados de logging.

### 3.1 Activación de logs en diferentes niveles (DEBUG, TRACE)

**Niveles de log**: Keycloak soporta los niveles estándar (ERROR, WARN, INFO, DEBUG, TRACE). En producción normalmente se usa INFO o WARN para reducir verbosidad, pero durante la depuración podemos necesitar DEBUG o incluso TRACE. DEBUG proporciona información detallada (por ejemplo, interacción con la base de datos, decisiones en los flujos de autenticación), mientras que TRACE es extremadamente detallado, incluyendo flujo interno completo y es poco común salvo en análisis muy específicos​.

**Configuración**: En Keycloak moderno (basado en Quarkus, 17+), podemos configurar el nivel de log global o por categorías vía parámetros al iniciar el servidor. Por ejemplo, para arrancar Keycloak en modo depuración global:

```bash
bin/kc.sh start --log-level=DEBUG
```

Esto establece DEBUG como nivel raíz. Alternativamente, podemos especificar niveles distintos por categoría. Por ejemplo:

```bash
bin/kc.sh start --log-level=INFO,org.keycloak.events:DEBUG,org.keycloak.authentication:TRACE
```

En este caso, el nivel global se mantiene en INFO, pero para la categoría `org.keycloak.events` (eventos) usamos DEBUG, y para `org.keycloak.authentication` (flujos de autenticación) elevamos a TRACE​. De esta forma focalizamos la verbosidad donde la necesitamos (p.ej., en eventos y autenticación) sin generar un exceso de log de otras partes.

**Categorías útiles para depuración**: Algunas categorías relevantes:

- `org.keycloak.events`: registros de eventos (LOGIN, LOGIN_ERROR, etc.) – en DEBUG podrían mostrar incluso eventos exitosos, no solo errores.
- `org.keycloak.authentication` o `org.keycloak.auth`: detalla la ejecución de cada ejecución en los flujos de autenticación (por ejemplo, pasos de un flujo con múltiples factores).
- `org.keycloak.protocol.oidc` y `org.keycloak.protocol.saml`: para mensajes relativos a OIDC/SAML respectivamente, incluyendo validaciones de parámetros, construcción de respuestas, etc.
- `org.keycloak.services` y `org.keycloak.models`: pueden brindar información de las operaciones internas (creación de sesiones, búsquedas de usuarios, etc.).
- `org.jboss.resteasy` (o Quarkus HTTP): a nivel TRACE puede listar cada petición HTTP que entra, con sus parámetros.

**Consideraciones**: Hay que tener precaución al usar niveles DEBUG/TRACE en entornos sensibles a rendimiento, ya que generan abundante información. Debe hacerse idealmente en entornos de prueba o temporalmente en producción al investigar un incidente específico. Tras obtener la información necesaria, conviene volver a niveles normales.

En entornos containerizados, si no se puede pasar parámetros fácilmente al comando de inicio, se pueden usar variables de entorno equivalentes (por ejemplo, `KC_LOG_LEVEL` para el nivel raíz, o `KC_LOG_LEVEL_<CATEGORY>` para categorías específicas, según la documentación de Keycloak). En Keycloak Legacy (WildFly), la configuración de log se hacía en `standalone.xml` o vía CLI de JBoss, definiendo los loggers y niveles.

### 3.2 Uso de logs estructurados (JSON) y su análisis

Analizar logs de texto plano puede ser engorroso, especialmente cuando queremos usar herramientas como Loki o Elasticsearch para búsquedas avanzadas. Keycloak soporta la salida de logs en formato JSON estructurado, lo que facilita su ingestión y análisis automático.

**Activar JSON logging**: Por defecto, Keycloak imprime logs no estructurados (texto simple) en la consola​. Para cambiar a JSON, se puede iniciar Keycloak con la opción:

```bash
bin/kc.sh start --log-console-output=json
```

Esto formateará todos los logs de consola como JSON válido. Cada entrada de log se convertirá en un objeto JSON con campos como timestamp, nivel, logger, mensaje, etc. Por ejemplo, un mensaje de inicio podría verse así en JSON:

```json
{   "timestamp":"2022-02-25T10:31:32.452+01:00",   "sequence":8442,   "loggerClassName":"org.jboss.logging.Logger",   "loggerName":"io.quarkus",   "level":"INFO",   "message":"Keycloak ... started in 3.253s. Listening on: http://0.0.0.0:8080",   "threadName":"main",   ... }
```

En el caso de eventos de autenticación, el campo `"message"` contendrá la cadena con los detalles (`type=LOGIN_ERROR, realmId=..., error=...`). Aunque esos detalles en la versión actual aparecen como parte del mensaje (no separados en campos JSON individuales), el resto de la estructura (timestamp, nivel, categoría, etc.) sí está separado, y podemos aplicar _parsers_ para extraer los datos clave del mensaje si es necesario.

**Análisis de logs JSON**: Una vez que los logs están en JSON, integrarlos con herramientas es más sencillo:

- **Elasticsearch/Kibana**: Se puede configurar un _ingest pipeline_ o usar Beats/Fluentd para enviar los JSON al cluster Elasticsearch. Al ser JSON, se pueden mapear campos como `level`, `loggerName` y potencialmente parsear el contenido de `message` para dividir `type`, `realmId`, `clientId`, `error`, etc., como campos separados. En Kibana, esto permite filtrar, por ejemplo, todos los logs donde `error` sea "invalid_user_credentials" o todos los `LOGIN_ERROR` de un realm específico, con simples consultas de campo en lugar de buscar texto libre.
    
- **Grafana Loki**: Loki puede trabajar con logs crudos pero es poderoso cuando se combina con la sintaxis LogQL para estructuras. Podemos enviar los logs JSON a Loki (por ejemplo, mediante Promtail leyendo desde stdout del contenedor). Luego en Grafana usar consultas como:
    
```logql
{app="keycloak", level="WARN", loggerName="org.keycloak.events"}    | json    | error != ""
```
    
    Esta consulta selecciona logs de la aplicación Keycloak con nivel WARN del logger de eventos, los pasa por un filtro `json` para parsear y luego filtra aquellos donde el campo `error` no esté vacío (es decir, login errors). De este modo, Loki extrae automáticamente los pares `error=invalid_user_credentials` del mensaje estructurado. Incluso podríamos hacer agregaciones o conteos en Loki, aunque para eso normalmente es mejor usar Prometheus con las métricas. Loki también permite correlacionar tiempo de logs con gráficos métricos en Grafana, facilitando ver, por ejemplo, qué logs de error ocurrieron durante un pico de uso.
    
- **Otras herramientas (Splunk, Graylog, etc.)**: Igualmente se benefician del formato JSON ya que minimiza la necesidad de expresiones regulares para parseo. Basta configurar la fuente para que trate cada línea como JSON.
    

En escenarios de depuración, usar logs JSON acelera las búsquedas. Por ejemplo, si queremos encontrar todos los intentos fallidos de cierto usuario, en Kibana podríamos buscar documentos donde `message` contenga `username=john.doe` (o si parseamos el message, directamente `username:"john.doe"` en campo). Con logs planos habrían requerido grep manual o patrones frágiles.

**Logs de auditoría y eventos**: Cabe destacar que, además de los logs de eventos de autenticación, Keycloak puede generar eventos de administrador (por cambios de configuración, creación de usuarios, etc.) y estos también pueden ser redirigidos a logs o almacenados. Usar JSON logging también beneficia esas entradas, manteniendo todo consistente para análisis histórico.

Por último, es importante deshabilitar la salida con color cuando se envían logs a sistemas externos (colores añaden caracteres ANSI que dificultan el parseo). En Keycloak, la salida JSON ya viene sin colores automáticamentepero si se estuviera usando texto plano y enviando a un agregador, conviene asegurarse de `--log-console-color=false` (valor por defecto en runtime estándar)​.

### 3.3 Integración con herramientas de análisis de logs (Loki, Elasticsearch, etc.)

Integrar Keycloak con herramientas de monitoreo de logs permite realizar una depuración más eficiente, sobre todo en entornos con múltiples instancias o microservicios. A continuación, algunos consejos para dicha integración:

- **Centralización de logs**: En producción se recomienda centralizar los logs de Keycloak en un sistema como Elasticsearch/Logstash/Kibana (ELK) o Grafana Loki, o incluso un SIEM para auditoría de seguridad. Keycloak puede enviar logs a stdout (ideal para contenedores) o a un archivo. Si se usa archivo, soluciones como Fluentd/FluentBit pueden leer ese archivo y enviarlo a un agregador. Si se usa stdout, Loki es particularmente sencillo de configurar (por ejemplo con el driver de logging de Docker para Loki, o con Promtail siguiendo los pods en Kubernetes).
    
- **Búsqueda y correlación**: Con todos los logs en un lugar, un ingeniero puede buscar un error específico en todos los nodos de Keycloak de una clúster a la vez. Por ejemplo: "buscar todas las ocurrencias de `LOGIN_ERROR` en la última hora". Esto es útil para ver si un problema es aislado o general. También se puede correlacionar con logs de otras aplicaciones: si una app integrada con Keycloak lanza un error, y en el mismo timestamp Keycloak muestra un `client_not_found`, podemos correlacionar que la causa fue esa.
    
- **Dashboards de logging**: Herramientas como Kibana o Grafana pueden construir dashboards a partir de logs. Por ejemplo, un panel que cuente cuántos `LOGIN_ERROR` de cada tipo ocurrieron hoy (esto se puede hacer tanto con logs parseados como con métricas, dando redundancia en monitoreo). Otro panel podría listar las últimas 10 excepciones no controladas en Keycloak (en caso de bugs). Loki tiene la capacidad de producir métricas temporales a partir de consultas (LogQL canary metrics), permitiendo, por ejemplo, alertar si aparece un log de error severo.
    
- **Loki + Tempo + Prometheus (Grafana LGTM stack)**: Grafana ofrece una integración interesante: Logs, Metrics, and Traces. Si usamos Prometheus para métricas de Keycloak, Loki para logs y Tempo (o Jaeger) para traces, Grafana puede vincularlos. Por ejemplo, desde un panel de Grafana de métricas, al detectar una anomalía, se puede hacer clic y ver los logs correlacionados en esa ventana de tiempo; o desde un log que contiene un `traceId`, Grafana puede ofrecer un enlace para abrir esa traza en Tempo. Esta sinergia hace que diagnosticar un problema complejo (que involucra métricas de rendimiento, errores en logs y seguimiento de la petición) sea mucho más ágil.
    
- **Ejemplo de consulta Loki**: Supongamos que queremos ver rápidamente en Grafana cuántos errores de cliente no encontrado ocurrieron. Podríamos usar:

```logql
count_over_time({container="keycloak"} |= "client_not_found" [1h])
```
        
    Esto contaría cuántas líneas contienen "client_not_found" en un lapso de 1 hora. Si hemos estructurado la salida en JSON, podríamos refinar con `| json` para asegurarnos de contar solo el campo error en eventos de tipo login de cliente.
    
- **Elasticsearch**: En Elasticsearch, aprovechar los campos estructurados nos permitiría, por ejemplo, hacer un gráfico de pastel de errores de login por tipo en Kibana Discover muy fácilmente, o buscar todos los eventos de un usuario dado en los últimos 30 días para auditoría. Además, se puede usar X-Pack Alerting o similares para notificar si aparecen ciertos patrones (p.ej., más de X errores de autenticación desde una misma IP, lo cual podría indicar un ataque; dicha situación se identifica en logs eventuales por la IP en el mensaje).
    

Integrar con estas herramientas de logging no solo ayuda en la resolución de problemas una vez han ocurrido, sino que también facilita ser proactivo. Por ejemplo, con las búsquedas adecuadas se puede detectar que un cliente ha estado recibiendo muchos `invalid_client_credentials` (quizá alguien actualizó el secreto en Keycloak pero no en la app) antes de que sea reportado como un incidente mayor.

En conclusión, combinar **logs detallados**, **métricas monitoreadas** y **trazas distribuidas**, junto con herramientas de agregación, ofrece un robusto conjunto de datos para diagnosticar problemas en Keycloak de manera eficiente.

A continuación, aplicaremos estos conceptos en algunos escenarios prácticos de fallo, mostrando paso a paso cómo identificar y resolver los problemas.